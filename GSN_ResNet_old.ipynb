{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea41522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchaudio in ./.venv/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: lightning in ./.venv/lib/python3.10/site-packages (2.6.0)\n",
      "Requirement already satisfied: kagglehub in ./.venv/lib/python3.10/site-packages (0.3.13)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: ipython in ./.venv/lib/python3.10/site-packages (8.37.0)\n",
      "Requirement already satisfied: soundfile in ./.venv/lib/python3.10/site-packages (0.13.1)\n",
      "Requirement already satisfied: wandb in ./.venv/lib/python3.10/site-packages (0.23.1)\n",
      "Requirement already satisfied: gdown in ./.venv/lib/python3.10/site-packages (5.2.0)\n",
      "Requirement already satisfied: torchcodec in ./.venv/lib/python3.10/site-packages (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.venv/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.10/site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.10/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: PyYAML<8.0,>5.4 in ./.venv/lib/python3.10/site-packages (from lightning) (6.0.3)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in ./.venv/lib/python3.10/site-packages (from lightning) (0.15.2)\n",
      "Requirement already satisfied: packaging<27.0,>=20.0 in ./.venv/lib/python3.10/site-packages (from lightning) (25.0)\n",
      "Requirement already satisfied: torchmetrics<3.0,>0.7.0 in ./.venv/lib/python3.10/site-packages (from lightning) (1.8.2)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in ./.venv/lib/python3.10/site-packages (from lightning) (4.67.1)\n",
      "Requirement already satisfied: pytorch-lightning in ./.venv/lib/python3.10/site-packages (from lightning) (2.6.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.10/site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.13.2)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (65.5.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.10/site-packages (from ipython) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from ipython) (1.3.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.10/site-packages (from ipython) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.10/site-packages (from ipython) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.10/site-packages (from ipython) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.10/site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./.venv/lib/python3.10/site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython) (0.2.14)\n",
      "Requirement already satisfied: cffi>=1.0 in ./.venv/lib/python3.10/site-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: click>=8.0.1 in ./.venv/lib/python3.10/site-packages (from wandb) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in ./.venv/lib/python3.10/site-packages (from wandb) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in ./.venv/lib/python3.10/site-packages (from wandb) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in ./.venv/lib/python3.10/site-packages (from wandb) (6.33.2)\n",
      "Requirement already satisfied: pydantic<3 in ./.venv/lib/python3.10/site-packages (from wandb) (2.12.5)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in ./.venv/lib/python3.10/site-packages (from wandb) (2.48.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.10/site-packages (from pydantic<3->wandb) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.10/site-packages (from pydantic<3->wandb) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->kagglehub) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->kagglehub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->kagglehub) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->kagglehub) (2025.11.12)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.10/site-packages (from gdown) (4.14.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.22.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in ./.venv/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in ./.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack_data->ipython) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack_data->ipython) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack_data->ipython) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrymer\u001b[0m (\u001b[33mrymer-agh-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instalacje\n",
    "!pip install pandas torch torchaudio lightning kagglehub scikit-learn ipython soundfile wandb gdown torchcodec\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import kagglehub\n",
    "import gdown\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "\n",
    "# Ustawienie ziarna losowo≈õci dla powtarzalno≈õci\n",
    "pl.seed_everything(42)\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18425de4",
   "metadata": {},
   "source": [
    "***Integracja dzia≈Çania g.collab vs lokalne***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b4c539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = os.path.exists('/content')\n",
    "\n",
    "local = not IS_COLAB ## powinno samo wykryƒá\n",
    "if local:\n",
    "    dataset_path = \"dataset\"\n",
    "else:\n",
    "    dataset_path = \"/content/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8197ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ju≈º istnieje w 'dataset'.\n",
      "Szumy ju≈º istniejƒÖ w 'dataset/noises'.\n",
      "Liczba dostƒôpnych plik√≥w szumu: 5\n"
     ]
    }
   ],
   "source": [
    "# 1. Pobieranie Datasetu MAD\n",
    "target_dir = dataset_path\n",
    "if os.path.exists(target_dir) and len(os.listdir(target_dir)) > 0:\n",
    "    print(f\"Dataset ju≈º istnieje w '{target_dir}'.\")\n",
    "else:\n",
    "    print(\"Pobieranie datasetu MAD...\")\n",
    "    path = kagglehub.dataset_download(\"junewookim/mad-dataset-military-audio-dataset\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    shutil.copytree(path, target_dir, dirs_exist_ok=True)\n",
    "    print(\"Pobrano dataset MAD.\")\n",
    "\n",
    "# 2. Pobieranie Szum√≥w (z Twojego pliku)\n",
    "noise_folder = dataset_path + \"/noises\"\n",
    "os.makedirs(noise_folder, exist_ok=True)\n",
    "url = \"https://drive.google.com/drive/folders/14Q_0KNDXACkFQ2oTF1T-gnjIaNbNuaKL?usp=sharing\"\n",
    "\n",
    "if not list(Path(noise_folder).glob(\"*.wav\")):\n",
    "    print(\"Pobieranie szum√≥w z Google Drive...\")\n",
    "    try:\n",
    "        gdown.download_folder(url, output=noise_folder, quiet=False, use_cookies=False)\n",
    "        print(\"Pobrano szumy.\")\n",
    "    except Exception as e:\n",
    "        print(f\"B≈ÇƒÖd pobierania szum√≥w: {e}\")\n",
    "else:\n",
    "    print(f\"Szumy ju≈º istniejƒÖ w '{noise_folder}'.\")\n",
    "\n",
    "noise_files = list(glob.glob(os.path.join(noise_folder, \"*.wav\")))\n",
    "print(f\"Liczba dostƒôpnych plik√≥w szumu: {len(noise_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d333492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Za≈Çadowano DataFrame: 6429 plik√≥w.\n"
     ]
    }
   ],
   "source": [
    "csv_path = dataset_path + \"/MAD_dataset/training.csv\"\n",
    "df_full = pd.read_csv(csv_path)\n",
    "\n",
    "# Mapowanie nazw kolumn\n",
    "rename_map = {\n",
    "    'filename': 'path',\n",
    "    'class': 'label',\n",
    "    'class_name': 'label'\n",
    "}\n",
    "df_full = df_full.rename(columns=rename_map)\n",
    "\n",
    "# Funkcja naprawiajƒÖca ≈õcie≈ºki\n",
    "def fix_path(path):\n",
    "    path = str(path)\n",
    "    if not path.startswith(\"training/\"):\n",
    "        return os.path.join(\"training\", path)\n",
    "    return path\n",
    "\n",
    "df_full['path'] = df_full['path'].apply(fix_path)\n",
    "print(f\"Za≈Çadowano DataFrame: {len(df_full)} plik√≥w.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdafda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedAudioDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, noise_files=None, training=True, target_len=150000, expansion_factor=1):\n",
    "        \"\"\"\n",
    "        expansion_factor: Ile razy powieliƒá dataset w jednej epoce.\n",
    "        Np. expansion_factor=5 sprawi, ≈ºe dataset 6000 plik√≥w bƒôdzie \"widziany\" jako 30000.\n",
    "        Ka≈ºda kopia dostanie innƒÖ, losowƒÖ augmentacjƒô.\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root_dir = os.path.abspath(str(root_dir).strip())\n",
    "        self.noise_files = noise_files\n",
    "        self.training = training\n",
    "        self.target_len = target_len\n",
    "        self.expansion_factor = expansion_factor if training else 1\n",
    "        self.target_sr = 48000\n",
    "\n",
    "        self.labels_to_indices = self.df.groupby('label').groups\n",
    "        self.all_labels = list(self.labels_to_indices.keys())\n",
    "\n",
    "        # 1. Cache SZUM√ìW\n",
    "        self.cached_noises = []\n",
    "        if noise_files:\n",
    "            print(f\"Cache'owanie {len(noise_files)} plik√≥w szumu...\")\n",
    "            for nf in noise_files:\n",
    "                try:\n",
    "                    wav, sr = torchaudio.load(nf)\n",
    "                    if sr != self.target_sr: wav = T.Resample(sr, self.target_sr)(wav)\n",
    "                    if wav.shape[0] > 1: wav = wav.mean(dim=0, keepdim=True)\n",
    "                    self.cached_noises.append(wav)\n",
    "                except: pass\n",
    "\n",
    "        # 2. Cache DANYCH TRENINGOWYCH\n",
    "        print(f\"≈Åadowanie {len(self.df)} plik√≥w treningowych z: {self.root_dir}\")\n",
    "        self.audio_cache = []\n",
    "        errors = 0\n",
    "        for i, row in enumerate(self.df.itertuples()):\n",
    "            csv_path = str(row.path).strip()\n",
    "            full_path = os.path.join(self.root_dir, csv_path)\n",
    "\n",
    "            try:\n",
    "                if not os.path.exists(full_path):\n",
    "                    raise FileNotFoundError(\"Plik nie istnieje\")\n",
    "\n",
    "                wav, sr = torchaudio.load(full_path)\n",
    "                if sr != self.target_sr: wav = T.Resample(sr, self.target_sr)(wav)\n",
    "                if wav.shape[0] > 1: wav = wav.mean(dim=0, keepdim=True)\n",
    "\n",
    "                if wav.shape[1] < self.target_len:\n",
    "                    wav = F.pad(wav, (0, self.target_len - wav.shape[1]))\n",
    "                elif wav.shape[1] > self.target_len:\n",
    "                    start = (wav.shape[1] - self.target_len) // 2\n",
    "                    wav = wav[:, start:start+self.target_len]\n",
    "\n",
    "                self.audio_cache.append(wav)\n",
    "\n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                self.audio_cache.append(torch.randn(1, self.target_len) * 0.001)\n",
    "\n",
    "        if errors > 0:\n",
    "            print(f\" uwaga: {errors} plik√≥w nie za≈Çadowano (wstawiono szum).\")\n",
    "        else:\n",
    "            print(\"sukces: Wszystkie pliki w pamiƒôci RAM.\")\n",
    "\n",
    "        if self.training and self.expansion_factor > 1:\n",
    "            print(f\"üöÄ DATASET ROZSZERZONY: {len(self.df)} plik√≥w -> {len(self)} wirtualnych pr√≥bek na epokƒô.\")\n",
    "\n",
    "    def aggressive_augment(self, waveform):\n",
    "        # Prosta agresywna augmentacja\n",
    "        gain = random.uniform(0.5, 1.5)\n",
    "        waveform = waveform * gain\n",
    "\n",
    "\n",
    "        #extra masking\n",
    "        #freq_mask = T.FrequencyMasking(freq_mask_param=5)\n",
    "        #time_mask = T.TimeMasking(time_mask_param=10)\n",
    "        #waveform = freq_mask(waveform)\n",
    "        #waveform = time_mask(waveform)\n",
    "\n",
    "        if self.cached_noises and random.random() > 0.3:\n",
    "            noise_wav = random.choice(self.cached_noises)\n",
    "            sig_len = waveform.shape[1]\n",
    "            if noise_wav.shape[1] < sig_len:\n",
    "                repeats = int(sig_len / noise_wav.shape[1]) + 1\n",
    "                curr_noise = noise_wav.repeat(1, repeats)[:, :sig_len]\n",
    "            else:\n",
    "                start = random.randint(0, noise_wav.shape[1] - sig_len)\n",
    "                curr_noise = noise_wav[:, start:start+sig_len]\n",
    "            snr_db = random.uniform(5.0, 25.0)\n",
    "            signal_power = waveform.norm(p=2)\n",
    "            noise_power = curr_noise.norm(p=2)\n",
    "            if noise_power > 0:\n",
    "                snr = 10 ** (snr_db / 20)\n",
    "                scale = signal_power / (noise_power * snr + 1e-9)\n",
    "                waveform = waveform + (curr_noise * scale)\n",
    "        return waveform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Dataset udaje, ≈ºe jest wiƒôkszy ni≈º w rzeczywisto≈õci\n",
    "        return len(self.df) * self.expansion_factor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Mapujemy wirtualny indeks na prawdziwy\n",
    "        real_idx = idx % len(self.df)\n",
    "\n",
    "        wav_a = self.audio_cache[real_idx].clone()\n",
    "        label_a = self.df.iloc[real_idx]['label']\n",
    "\n",
    "        if self.training:\n",
    "            wav_a = self.aggressive_augment(wav_a)\n",
    "\n",
    "        # Positive\n",
    "        idxs_p = self.labels_to_indices[label_a]\n",
    "        possible_p = idxs_p.drop(real_idx, errors='ignore')\n",
    "        idx_p = random.choice(possible_p) if len(possible_p) > 0 else real_idx\n",
    "\n",
    "        wav_p = self.audio_cache[idx_p].clone()\n",
    "        if self.training: wav_p = self.aggressive_augment(wav_p)\n",
    "\n",
    "        # Negative\n",
    "        label_n = random.choice([l for l in self.all_labels if l != label_a])\n",
    "        idx_n = random.choice(self.labels_to_indices[label_n])\n",
    "        wav_n = self.audio_cache[idx_n].clone()\n",
    "        if self.training: wav_n = self.aggressive_augment(wav_n)\n",
    "\n",
    "        return wav_a, wav_p, wav_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f36d18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetTripletGPU(pl.LightningModule):\n",
    "    def __init__(self, df, root_dir, noise_files, margin=1.0, learning_rate=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['df', 'root_dir', 'noise_files'])\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.noise_files = noise_files\n",
    "\n",
    "        # 1. Transformacja na GPU\n",
    "        self.spec_layer = T.MelSpectrogram(\n",
    "            sample_rate=48000, n_fft=1024, hop_length=512, n_mels=64, f_min=20, f_max=24000\n",
    "        )\n",
    "        self.db_layer = T.AmplitudeToDB()\n",
    "\n",
    "        # 2. Backbone\n",
    "        self.backbone = resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # Dostosowanie ResNet do 1 kana≈Çu\n",
    "        original_conv1 = self.backbone.conv1\n",
    "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        with torch.no_grad():\n",
    "            self.backbone.conv1.weight.data = original_conv1.weight.data.sum(dim=1, keepdim=True)\n",
    "\n",
    "        # V2 version with more complex head\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(512, 512, bias=False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 256, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(256, 256, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "        # V3 version even bigger head\n",
    "        # self.backbone.fc = nn.Sequential(\n",
    "        #     nn.Linear(512, 1024, bias=False),\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Dropout(0.2),\n",
    "        #     nn.Linear(1024, 512, bias=False),\n",
    "        #     nn.BatchNorm1d(512),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Dropout(0.2),\n",
    "        #     nn.Linear(512, 256, bias=False),\n",
    "        #     nn.BatchNorm1d(256),\n",
    "        #     nn.LeakyReLU(0.1, inplace=True),\n",
    "        #     nn.Dropout(0.2),\n",
    "        #     nn.Linear(256, 256, bias=False),\n",
    "        #     nn.BatchNorm1d(256),\n",
    "        #     nn.LeakyReLU(0.1, inplace=True),\n",
    "        #     nn.Linear(256, 128)\n",
    "        # )\n",
    "\n",
    "        # self.backbone.fc = nn.Sequential(\n",
    "        #     nn.Linear(512, 512, bias=False),\n",
    "        #     nn.BatchNorm1d(512),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.Linear(512, 256, bias=False),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Dropout(0.2),\n",
    "        #     nn.Linear(256, 256, bias=False),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Linear(256, 128)\n",
    "        # )\n",
    "\n",
    "\n",
    "        self.loss_fn = nn.TripletMarginLoss(margin=margin, p=2)\n",
    "\n",
    "        #soft margin with cosine similarity\n",
    "        #self.loss_fn = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1 - F.cosine_similarity(x, y))\n",
    "\n",
    "    def compute_features(self, wav):\n",
    "        # To dzieje siƒô na GPU!\n",
    "        spec = self.spec_layer(wav)\n",
    "        spec = self.db_layer(spec)\n",
    "        spec = (spec - spec.mean()) / (spec.std() + 1e-6)\n",
    "        return self.backbone(spec)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.compute_features(x), p=2, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        wav_a, wav_p, wav_n = batch\n",
    "        emb_a = self(wav_a)\n",
    "        emb_p = self(wav_p)\n",
    "        emb_n = self(wav_n)\n",
    "\n",
    "        loss = self.loss_fn(emb_a, emb_p, emb_n)\n",
    "        acc = (F.pairwise_distance(emb_a, emb_p) < F.pairwise_distance(emb_a, emb_n)).float().mean()\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        wav_a, wav_p, wav_n = batch\n",
    "        emb_a = self(wav_a)\n",
    "        emb_p = self(wav_p)\n",
    "        emb_n = self(wav_n)\n",
    "\n",
    "        loss = self.loss_fn(emb_a, emb_p, emb_n)\n",
    "        acc = (F.pairwise_distance(emb_a, emb_p) < F.pairwise_distance(emb_a, emb_n)).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        wav_a, wav_p, wav_n = batch\n",
    "        emb_a = self(wav_a)\n",
    "        emb_p = self(wav_p)\n",
    "        emb_n = self(wav_n)\n",
    "\n",
    "        loss = self.loss_fn(emb_a, emb_p, emb_n)\n",
    "        acc = (F.pairwise_distance(emb_a, emb_p) < F.pairwise_distance(emb_a, emb_n)).float().mean()\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_df, _ = train_test_split(self.df, test_size=0.2, random_state=42, stratify=self.df['label'])\n",
    "        ds = CachedAudioDataset(\n",
    "            train_df,\n",
    "            self.root_dir,\n",
    "            self.noise_files,\n",
    "            training=True,\n",
    "            expansion_factor=5\n",
    "        )\n",
    "        return DataLoader(ds, batch_size=64, shuffle=True, num_workers=2, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        _, val_df = train_test_split(self.df, test_size=0.2, random_state=42, stratify=self.df['label'])\n",
    "        ds = CachedAudioDataset(val_df, self.root_dir, noise_files=None, training=False)\n",
    "        return DataLoader(ds, batch_size=64, shuffle=False, num_workers=2, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4714d369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Checkpointy z tego treningu trafiƒÖ do: checkpoints/ResNet_Triplet_big_head_more_dropout_2026-01-15_00-26-48\n",
      "üöÄ Rozpoczynam trening: ResNet_Triplet_big_head_more_dropout_2026-01-15_00-26-48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb/run-20260115_002649-m5hsmapd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deep-neural-network-course/siamese-audio-classifier/runs/m5hsmapd' target=\"_blank\">ResNet_Triplet_big_head_more_dropout_2026-01-15_00-26-48</a></strong> to <a href='https://wandb.ai/deep-neural-network-course/siamese-audio-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deep-neural-network-course/siamese-audio-classifier' target=\"_blank\">https://wandb.ai/deep-neural-network-course/siamese-audio-classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deep-neural-network-course/siamese-audio-classifier/runs/m5hsmapd' target=\"_blank\">https://wandb.ai/deep-neural-network-course/siamese-audio-classifier/runs/m5hsmapd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type              | Params | Mode  | FLOPs\n",
      "-----------------------------------------------------------------\n",
      "0 | spec_layer | MelSpectrogram    | 0      | train | 0    \n",
      "1 | db_layer   | AmplitudeToDB     | 0      | train | 0    \n",
      "2 | backbone   | ResNet            | 11.7 M | train | 0    \n",
      "3 | loss_fn    | TripletMarginLoss | 0      | train | 0    \n",
      "-----------------------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.656    Total estimated model params size (MB)\n",
      "86        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "0         Total Flops\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b4d0f8a73d474591e3eecc2c590b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "≈Åadowanie 1286 plik√≥w treningowych z: /home/iwo/GSN/siamese-audio-classifier/dataset/MAD_dataset\n",
      "sukces: Wszystkie pliki w pamiƒôci RAM.\n",
      "Cache'owanie 5 plik√≥w szumu...\n",
      "≈Åadowanie 5143 plik√≥w treningowych z: /home/iwo/GSN/siamese-audio-classifier/dataset/MAD_dataset\n",
      "sukces: Wszystkie pliki w pamiƒôci RAM.\n",
      "üöÄ DATASET ROZSZERZONY: 5143 plik√≥w -> 25715 wirtualnych pr√≥bek na epokƒô.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3639b0fc06c94197962e0ef5993897d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0cc68cc1d8740f59090e88e0c348094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523f40dff37a4bcea385ff486e9b44ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc457bd481a4eae88e5e3c4b67d5621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6de383786c4772aeded797ab442abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa5d171eb5f4dbf9a1b0c0c44b9bd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befd7da020604ef8878bad1c86850357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd49b8334b044b728da515f391e3c352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5d378e2f414f98b008f2e817c5ced0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a223ea3d654d4c3b9d9e647702aaa341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda19062d8404285a3d96614f7f52689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fab2c9933949d2aa539c9379472d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e309068418409bb695c1013234fd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef04382dcab4d5797da761dd9db74e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48992c97b3264e90ad46288354a6e85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8368b8d18474474f94d8414030d7ba2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a233ba5d4e44df08b925d79fd95766a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e88c215707c4ba9815d68a8ed92401c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245b13f7f8c143b4a93ac34f82315b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed79bc1b3a524ab087be2f4b6747d7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a707aa98ec46198244b2f5a2632bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trening zako≈Ñczony.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train_acc</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñà‚ñÜ‚ñà‚ñÜ‚ñÉ‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñà</td></tr><tr><td>train_loss</td><td>‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>trainer/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_acc</td><td>‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñà</td></tr><tr><td>val_loss</td><td>‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>train_acc</td><td>1</td></tr><tr><td>train_loss</td><td>0.00304</td></tr><tr><td>trainer/global_step</td><td>8039</td></tr><tr><td>val_acc</td><td>0.97667</td></tr><tr><td>val_loss</td><td>0.03515</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ResNet_Triplet_big_head_more_dropout_2026-01-15_00-26-48</strong> at: <a href='https://wandb.ai/deep-neural-network-course/siamese-audio-classifier/runs/m5hsmapd' target=\"_blank\">https://wandb.ai/deep-neural-network-course/siamese-audio-classifier/runs/m5hsmapd</a><br> View project at: <a href='https://wandb.ai/deep-neural-network-course/siamese-audio-classifier' target=\"_blank\">https://wandb.ai/deep-neural-network-course/siamese-audio-classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>wandb/run-20260115_002649-m5hsmapd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# ==========================================\n",
    "# KONFIGURACJA UNIKALNEGO TRENINGU\n",
    "# ==========================================\n",
    "\n",
    "#OPCJALNIE: customowy dodatek nazy runu\n",
    "model_big_name = \"ResNet_Triplet_big_head_more_dropout\"\n",
    "\n",
    "\n",
    "# 1. Tworzymy unikalnƒÖ nazwƒô folderu na podstawie daty i godziny\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "run_name = f\"{model_big_name}_{timestamp}\"\n",
    "checkpoint_dir = os.path.join(\"checkpoints\", run_name)\n",
    "\n",
    "# Tworzymy folder fizycznie\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "print(f\"üìÇ Checkpointy z tego treningu trafiƒÖ do: {checkpoint_dir}\")\n",
    "\n",
    "# ==========================================\n",
    "# CALLBACKI I LOGGER\n",
    "# ==========================================\n",
    "\n",
    "# 2. Checkpoint najlepszego modelu wg Accuracy\n",
    "checkpoint_best = ModelCheckpoint(\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    "    dirpath=checkpoint_dir,\n",
    "    filename=\"best-epoch={epoch:02d}-acc={val_acc:.4f}\",\n",
    "    save_top_k=1,\n",
    "    auto_insert_metric_name=False\n",
    ")\n",
    "\n",
    "# 3. Checkpoint okresowy (co 5 epok)\n",
    "checkpoint_periodic = ModelCheckpoint(\n",
    "    dirpath=checkpoint_dir,\n",
    "    filename=\"periodic-epoch={epoch:02d}\",\n",
    "    every_n_epochs=5,\n",
    "    save_last=True,\n",
    "    save_top_k=-1\n",
    ")\n",
    "\n",
    "# 4. WandB Logger\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"siamese-audio-classifier\",\n",
    "    entity=\"deep-neural-network-course\",\n",
    "    name=run_name,\n",
    "    log_model=False\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# START TRENINGU\n",
    "# ==========================================\n",
    "\n",
    "if local:\n",
    "    ROOT_DIR = \"dataset/MAD_dataset\"  # upewnij siƒô, ≈ºe to poprawna ≈õcie≈ºka!\n",
    "else:\n",
    "    ROOT_DIR = \"/content/dataset/MAD_dataset\" # upewnij siƒô, ≈ºe to poprawna ≈õcie≈ºka!\n",
    "\n",
    "\n",
    "model = ResNetTripletGPU(\n",
    "    df=df_full,\n",
    "    root_dir=ROOT_DIR,\n",
    "    noise_files=noise_files,\n",
    "    margin=0.5\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_best, checkpoint_periodic],\n",
    "    log_every_n_steps=10,\n",
    "    precision=32,\n",
    "    gradient_clip_val=1.0\n",
    ")\n",
    "\n",
    "print(f\"üöÄ Rozpoczynam trening: {run_name}\")\n",
    "trainer.fit(model)\n",
    "\n",
    "print(\"Trening zako≈Ñczony.\")\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59ab8ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è KONFIGURACJA ≈öRODOWISKA I FOLDER√ìW...\n",
      "‚úÖ Folder na wyniki: /home/iwo/GSN/siamese-audio-classifier/Models/ResNet_Triplet_big_head_more_dropout_2026-01-15_00-26-48\n",
      "\n",
      "üìä ROZPOCZYNAM TESTOWANIE NAJLEPSZEGO MODELU...\n",
      "≈Åadowanie 1037 plik√≥w treningowych z: /home/iwo/GSN/siamese-audio-classifier/dataset/MAD_dataset\n",
      "sukces: Wszystkie pliki w pamiƒôci RAM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fea47f705ea4bd4b4530a4399948f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "       Test metric             DataLoader 0\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "        test_acc            0.9334619045257568\n",
      "        test_loss           0.09609925001859665\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "Czas testowania: 1872.02 ms\n",
      "≈öredni czas inferencji na pr√≥bkƒô: 1.8052 ms\n",
      "\n",
      "üìù WYNIKI BEST: ACC=0.9335, LOSS=0.0961\n",
      "\n",
      "üöö Zapis wynik√≥w do folderu: /home/iwo/GSN/siamese-audio-classifier/Models/ResNet_Triplet_big_head_more_dropout_2026-01-15_00-26-48\n",
      "‚úÖ Zapisano NAJLEPSZY model: bigger_head_more_dropout_oldBEST_ACC=0.9335_LOSS=0.0961_time=1.8052.ckpt\n",
      "‚ö†Ô∏è Nie znaleziono pliku 'last.ckpt'. Je≈õli chcesz, ustaw save_last=True przy treningu.\n",
      "\n",
      "üéâ Zako≈Ñczono! Sprawd≈∫ folder z wynikami.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "#OPCJALNIE: customowy dodatek nazy runu\n",
    "model_pet_name = \"bigger_head_more_dropout_old\" # np. V1, V2 itp.\n",
    "\n",
    "print(\"üõ†Ô∏è KONFIGURACJA ≈öRODOWISKA I FOLDER√ìW...\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    # --- Montowanie Dysku Google ---\n",
    "    if os.path.exists('/content/drive') and not os.path.exists('/content/drive/MyDrive'):\n",
    "        print(\"‚ö†Ô∏è Wykryto b≈Çƒôdne montowanie. Naprawiam...\")\n",
    "        shutil.rmtree('/content/drive')\n",
    "    if not os.path.exists('/content/drive'):\n",
    "        drive.mount('/content/drive', force_remount=True)\n",
    "    BASE_DIR = \"/content/drive/MyDrive/studia/ProjektGsn/Models\"\n",
    "else:\n",
    "    # ≈öcie≈ºka lokalna\n",
    "    BASE_DIR = os.path.abspath(\"Models\")\n",
    "\n",
    "# Tworzymy unikalnƒÖ nazwƒô runu\n",
    "if 'run_name' not in globals():\n",
    "    run_name = f\"Run_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "\n",
    "TARGET_RUN_DIR = os.path.join(BASE_DIR, run_name)\n",
    "os.makedirs(TARGET_RUN_DIR, exist_ok=True)\n",
    "print(f\"‚úÖ Folder na wyniki: {TARGET_RUN_DIR}\")\n",
    "\n",
    "# ==========================================\n",
    "# Testowanie najlepszego modelu\n",
    "# ==========================================\n",
    "print(\"\\nüìä ROZPOCZYNAM TESTOWANIE NAJLEPSZEGO MODELU...\")\n",
    "\n",
    "if 'ROOT_DIR' not in globals():\n",
    "    ROOT_DIR = \"dataset/MAD_dataset\" if not IS_COLAB else \"/content/dataset/MAD_dataset\"\n",
    "\n",
    "test_csv_path = os.path.join(ROOT_DIR, \"test.csv\")\n",
    "if not os.path.exists(test_csv_path):\n",
    "    test_csv_path = os.path.join(ROOT_DIR, \"test.csv\")  # fallback lokalny\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "def fix_test_path(path):\n",
    "    path = str(path)\n",
    "    if not path.startswith(\"test/\") and not path.startswith(\"training/\"):\n",
    "        return os.path.join(\"test\", path)\n",
    "    return path\n",
    "\n",
    "df_test['path'] = df_test['path'].apply(fix_test_path)\n",
    "\n",
    "test_ds = CachedAudioDataset(df_test, root_dir=ROOT_DIR, noise_files=None, training=False, expansion_factor=1)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Pobieranie ≈õcie≈ºki najlepszego modelu\n",
    "if 'checkpoint_best' in globals():\n",
    "    best_local_path = checkpoint_best.best_model_path\n",
    "    last_local_path = checkpoint_best.last_model_path\n",
    "else:\n",
    "    local_dir = f\"checkpoints/{run_name}\"\n",
    "    files = glob.glob(f\"{local_dir}/best*.ckpt\")\n",
    "    best_local_path = files[0] if files else None\n",
    "    last_local_path = os.path.join(local_dir, \"last.ckpt\")\n",
    "\n",
    "if not best_local_path or not os.path.exists(best_local_path):\n",
    "    raise FileNotFoundError(\"Nie znaleziono modelu 'best' w folderze checkpoints!\")\n",
    "\n",
    "trainer.logger = None  # wy≈ÇƒÖcz logger\n",
    "best_model = ResNetTripletGPU.load_from_checkpoint(best_local_path, df=df_full, root_dir=ROOT_DIR, noise_files=[])\n",
    "time_ms_start = datetime.datetime.now()\n",
    "results = trainer.test(best_model, dataloaders=test_loader)\n",
    "time_ms_end = datetime.datetime.now()\n",
    "time_taken = (time_ms_end - time_ms_start).total_seconds() * 1000\n",
    "print(f\"Czas testowania: {time_taken:.2f} ms\")\n",
    "avg_inference_time = time_taken / len(test_ds)\n",
    "print(f\"≈öredni czas inferencji na pr√≥bkƒô: {avg_inference_time:.4f} ms\")\n",
    "\n",
    "acc, loss = results[0]['test_acc'], results[0]['test_loss']\n",
    "\n",
    "print(f\"\\nüìù WYNIKI BEST: ACC={acc:.4f}, LOSS={loss:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# Kopiowanie lub zapis lokalny\n",
    "# ==========================================\n",
    "print(f\"\\nüöö Zapis wynik√≥w do folderu: {TARGET_RUN_DIR}\")\n",
    "\n",
    "# A) Zapis najlepszego modelu\n",
    "best_filename = f\"{model_pet_name}BEST_ACC={acc:.4f}_LOSS={loss:.4f}_time={avg_inference_time:.4f}.ckpt\"\n",
    "target_best = os.path.join(TARGET_RUN_DIR, best_filename)\n",
    "try:\n",
    "    shutil.copy(best_local_path, target_best)\n",
    "    print(f\"‚úÖ Zapisano NAJLEPSZY model: {best_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå B≈ÇƒÖd kopiowania BEST: {e}\")\n",
    "\n",
    "# B) Zapis ostatniego stanu\n",
    "if last_local_path and os.path.exists(last_local_path):\n",
    "    last_filename = \"LAST_STATE.ckpt\"\n",
    "    target_last = os.path.join(TARGET_RUN_DIR, last_filename)\n",
    "    try:\n",
    "        shutil.copy(last_local_path, target_last)\n",
    "        print(f\"‚úÖ Zapisano OSTATNI model: {last_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå B≈ÇƒÖd kopiowania LAST: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nie znaleziono pliku 'last.ckpt'. Je≈õli chcesz, ustaw save_last=True przy treningu.\")\n",
    "\n",
    "print(\"\\nüéâ Zako≈Ñczono! Sprawd≈∫ folder z wynikami.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
