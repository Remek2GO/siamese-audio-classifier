{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea41522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalacje\n",
    "!pip install pandas torch torchaudio lightning kagglehub scikit-learn ipython soundfile wandb gdown torchcodec\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import kagglehub\n",
    "import gdown\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "\n",
    "# Ustawienie ziarna losowoÅ›ci dla powtarzalnoÅ›ci\n",
    "pl.seed_everything(42)\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18425de4",
   "metadata": {},
   "source": [
    "***Integracja dziaÅ‚ania g.collab vs lokalne***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = os.path.exists('/content')\n",
    "\n",
    "local = not IS_COLAB ## powinno samo wykryÄ‡\n",
    "if local:\n",
    "    dataset_path = \"dataset\"\n",
    "else:\n",
    "    dataset_path = \"/content/dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8197ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pobieranie Datasetu MAD\n",
    "target_dir = dataset_path\n",
    "if os.path.exists(target_dir) and len(os.listdir(target_dir)) > 0:\n",
    "    print(f\"Dataset juÅ¼ istnieje w '{target_dir}'.\")\n",
    "else:\n",
    "    print(\"Pobieranie datasetu MAD...\")\n",
    "    path = kagglehub.dataset_download(\"junewookim/mad-dataset-military-audio-dataset\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    shutil.copytree(path, target_dir, dirs_exist_ok=True)\n",
    "    print(\"Pobrano dataset MAD.\")\n",
    "\n",
    "# 2. Pobieranie SzumÃ³w (z Twojego pliku)\n",
    "noise_folder = dataset_path + \"/noises\"\n",
    "os.makedirs(noise_folder, exist_ok=True)\n",
    "url = \"https://drive.google.com/drive/folders/14Q_0KNDXACkFQ2oTF1T-gnjIaNbNuaKL?usp=sharing\"\n",
    "\n",
    "if not list(Path(noise_folder).glob(\"*.wav\")):\n",
    "    print(\"Pobieranie szumÃ³w z Google Drive...\")\n",
    "    try:\n",
    "        gdown.download_folder(url, output=noise_folder, quiet=False, use_cookies=False)\n",
    "        print(\"Pobrano szumy.\")\n",
    "    except Exception as e:\n",
    "        print(f\"BÅ‚Ä…d pobierania szumÃ³w: {e}\")\n",
    "else:\n",
    "    print(f\"Szumy juÅ¼ istniejÄ… w '{noise_folder}'.\")\n",
    "\n",
    "noise_files = list(glob.glob(os.path.join(noise_folder, \"*.wav\")))\n",
    "print(f\"Liczba dostÄ™pnych plikÃ³w szumu: {len(noise_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d333492",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = dataset_path + \"/MAD_dataset/training.csv\"\n",
    "df_full = pd.read_csv(csv_path)\n",
    "\n",
    "# Mapowanie nazw kolumn\n",
    "rename_map = {\n",
    "    'filename': 'path',\n",
    "    'class': 'label',\n",
    "    'class_name': 'label'\n",
    "}\n",
    "df_full = df_full.rename(columns=rename_map)\n",
    "\n",
    "# Funkcja naprawiajÄ…ca Å›cieÅ¼ki\n",
    "def fix_path(path):\n",
    "    path = str(path)\n",
    "    if not path.startswith(\"training/\"):\n",
    "        return os.path.join(\"training\", path)\n",
    "    return path\n",
    "\n",
    "df_full['path'] = df_full['path'].apply(fix_path)\n",
    "print(f\"ZaÅ‚adowano DataFrame: {len(df_full)} plikÃ³w.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdafda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedAudioDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, noise_files=None, training=True, target_len=150000, expansion_factor=1):\n",
    "        \"\"\"\n",
    "        expansion_factor: Ile razy powieliÄ‡ dataset w jednej epoce.\n",
    "        Np. expansion_factor=5 sprawi, Å¼e dataset 6000 plikÃ³w bÄ™dzie \"widziany\" jako 30000.\n",
    "        KaÅ¼da kopia dostanie innÄ…, losowÄ… augmentacjÄ™.\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root_dir = os.path.abspath(str(root_dir).strip())\n",
    "        self.noise_files = noise_files\n",
    "        self.training = training\n",
    "        self.target_len = target_len\n",
    "        self.expansion_factor = expansion_factor if training else 1\n",
    "        self.target_sr = 48000\n",
    "\n",
    "        self.labels_to_indices = self.df.groupby('label').groups\n",
    "        self.all_labels = list(self.labels_to_indices.keys())\n",
    "\n",
    "        # 1. Cache SZUMÃ“W\n",
    "        self.cached_noises = []\n",
    "        if noise_files:\n",
    "            print(f\"Cache'owanie {len(noise_files)} plikÃ³w szumu...\")\n",
    "            for nf in noise_files:\n",
    "                try:\n",
    "                    wav, sr = torchaudio.load(nf)\n",
    "                    if sr != self.target_sr: wav = T.Resample(sr, self.target_sr)(wav)\n",
    "                    if wav.shape[0] > 1: wav = wav.mean(dim=0, keepdim=True)\n",
    "                    self.cached_noises.append(wav)\n",
    "                except: pass\n",
    "\n",
    "        # 2. Cache DANYCH TRENINGOWYCH\n",
    "        print(f\"Åadowanie {len(self.df)} plikÃ³w treningowych z: {self.root_dir}\")\n",
    "        self.audio_cache = []\n",
    "        errors = 0\n",
    "        for i, row in enumerate(self.df.itertuples()):\n",
    "            csv_path = str(row.path).strip()\n",
    "            full_path = os.path.join(self.root_dir, csv_path)\n",
    "\n",
    "            try:\n",
    "                if not os.path.exists(full_path):\n",
    "                    raise FileNotFoundError(\"Plik nie istnieje\")\n",
    "\n",
    "                wav, sr = torchaudio.load(full_path)\n",
    "                if sr != self.target_sr: wav = T.Resample(sr, self.target_sr)(wav)\n",
    "                if wav.shape[0] > 1: wav = wav.mean(dim=0, keepdim=True)\n",
    "\n",
    "                if wav.shape[1] < self.target_len:\n",
    "                    wav = F.pad(wav, (0, self.target_len - wav.shape[1]))\n",
    "                elif wav.shape[1] > self.target_len:\n",
    "                    start = (wav.shape[1] - self.target_len) // 2\n",
    "                    wav = wav[:, start:start+self.target_len]\n",
    "\n",
    "                self.audio_cache.append(wav)\n",
    "\n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                self.audio_cache.append(torch.randn(1, self.target_len) * 0.001)\n",
    "\n",
    "        if errors > 0:\n",
    "            print(f\" uwaga: {errors} plikÃ³w nie zaÅ‚adowano (wstawiono szum).\")\n",
    "        else:\n",
    "            print(\"sukces: Wszystkie pliki w pamiÄ™ci RAM.\")\n",
    "\n",
    "        if self.training and self.expansion_factor > 1:\n",
    "            print(f\"ðŸš€ DATASET ROZSZERZONY: {len(self.df)} plikÃ³w -> {len(self)} wirtualnych prÃ³bek na epokÄ™.\")\n",
    "\n",
    "    def aggressive_augment(self, waveform):\n",
    "        # Prosta agresywna augmentacja\n",
    "        gain = random.uniform(0.5, 1.5)\n",
    "        waveform = waveform * gain\n",
    "\n",
    "\n",
    "        #extra masking\n",
    "        #freq_mask = T.FrequencyMasking(freq_mask_param=5)\n",
    "        #time_mask = T.TimeMasking(time_mask_param=10)\n",
    "        #waveform = freq_mask(waveform)\n",
    "        #waveform = time_mask(waveform)\n",
    "\n",
    "        if self.cached_noises and random.random() > 0.3:\n",
    "            noise_wav = random.choice(self.cached_noises)\n",
    "            sig_len = waveform.shape[1]\n",
    "            if noise_wav.shape[1] < sig_len:\n",
    "                repeats = int(sig_len / noise_wav.shape[1]) + 1\n",
    "                curr_noise = noise_wav.repeat(1, repeats)[:, :sig_len]\n",
    "            else:\n",
    "                start = random.randint(0, noise_wav.shape[1] - sig_len)\n",
    "                curr_noise = noise_wav[:, start:start+sig_len]\n",
    "            snr_db = random.uniform(5.0, 25.0)\n",
    "            signal_power = waveform.norm(p=2)\n",
    "            noise_power = curr_noise.norm(p=2)\n",
    "            if noise_power > 0:\n",
    "                snr = 10 ** (snr_db / 20)\n",
    "                scale = signal_power / (noise_power * snr + 1e-9)\n",
    "                waveform = waveform + (curr_noise * scale)\n",
    "        return waveform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Dataset udaje, Å¼e jest wiÄ™kszy niÅ¼ w rzeczywistoÅ›ci\n",
    "        return len(self.df) * self.expansion_factor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Mapujemy wirtualny indeks na prawdziwy\n",
    "        real_idx = idx % len(self.df)\n",
    "\n",
    "        wav_a = self.audio_cache[real_idx].clone()\n",
    "        label_a = self.df.iloc[real_idx]['label']\n",
    "\n",
    "        if self.training:\n",
    "            wav_a = self.aggressive_augment(wav_a)\n",
    "\n",
    "        # Positive\n",
    "        idxs_p = self.labels_to_indices[label_a]\n",
    "        possible_p = idxs_p.drop(real_idx, errors='ignore')\n",
    "        idx_p = random.choice(possible_p) if len(possible_p) > 0 else real_idx\n",
    "\n",
    "        wav_p = self.audio_cache[idx_p].clone()\n",
    "        if self.training: wav_p = self.aggressive_augment(wav_p)\n",
    "\n",
    "        # Negative\n",
    "        label_n = random.choice([l for l in self.all_labels if l != label_a])\n",
    "        idx_n = random.choice(self.labels_to_indices[label_n])\n",
    "        wav_n = self.audio_cache[idx_n].clone()\n",
    "        if self.training: wav_n = self.aggressive_augment(wav_n)\n",
    "\n",
    "        return wav_a, wav_p, wav_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetTripletGPU(pl.LightningModule):\n",
    "    def __init__(self, df, root_dir, noise_files, margin=1.0, learning_rate=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['df', 'root_dir', 'noise_files'])\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.noise_files = noise_files\n",
    "\n",
    "        # 1. Transformacja na GPU\n",
    "        self.spec_layer = T.MelSpectrogram(\n",
    "            sample_rate=48000, n_fft=1024, hop_length=512, n_mels=64, f_min=20, f_max=24000\n",
    "        )\n",
    "        self.db_layer = T.AmplitudeToDB()\n",
    "\n",
    "        # 2. Backbone\n",
    "        self.backbone = resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # Dostosowanie ResNet do 1 kanaÅ‚u\n",
    "        original_conv1 = self.backbone.conv1\n",
    "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        with torch.no_grad():\n",
    "            self.backbone.conv1.weight.data = original_conv1.weight.data.sum(dim=1, keepdim=True)\n",
    "\n",
    "        # V2 version with more complex head\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(512, 512, bias=False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 256, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(256, 256, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "        # V3 version even bigger head\n",
    "        # self.backbone.fc = nn.Sequential(\n",
    "        #     nn.Linear(512, 1024, bias=False),\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Dropout(0.2),\n",
    "        #     nn.Linear(1024, 512, bias=False),\n",
    "        #     nn.BatchNorm1d(512),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Dropout(0.2),\n",
    "        #     nn.Linear(512, 256, bias=False),\n",
    "        #     nn.BatchNorm1d(256),\n",
    "        #     nn.LeakyReLU(0.1, inplace=True),\n",
    "        #     nn.Dropout(0.2),\n",
    "        #     nn.Linear(256, 256, bias=False),\n",
    "        #     nn.BatchNorm1d(256),\n",
    "        #     nn.LeakyReLU(0.1, inplace=True),\n",
    "        #     nn.Linear(256, 128)\n",
    "        # )\n",
    "\n",
    "        # self.backbone.fc = nn.Sequential(\n",
    "        #     nn.Linear(512, 512, bias=False),\n",
    "        #     nn.BatchNorm1d(512),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Dropout(0.3),\n",
    "        #     nn.Linear(512, 256, bias=False),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Dropout(0.2),\n",
    "        #     nn.Linear(256, 256, bias=False),\n",
    "        #     nn.ReLU(inplace=True),\n",
    "        #     nn.Linear(256, 128)\n",
    "        # )\n",
    "\n",
    "\n",
    "        self.loss_fn = nn.TripletMarginLoss(margin=margin, p=2)\n",
    "\n",
    "        #soft margin with cosine similarity\n",
    "        #self.loss_fn = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1 - F.cosine_similarity(x, y))\n",
    "\n",
    "    def compute_features(self, wav):\n",
    "        # To dzieje siÄ™ na GPU!\n",
    "        spec = self.spec_layer(wav)\n",
    "        spec = self.db_layer(spec)\n",
    "        spec = (spec - spec.mean()) / (spec.std() + 1e-6)\n",
    "        return self.backbone(spec)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.compute_features(x), p=2, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        wav_a, wav_p, wav_n = batch\n",
    "        emb_a = self(wav_a)\n",
    "        emb_p = self(wav_p)\n",
    "        emb_n = self(wav_n)\n",
    "\n",
    "        loss = self.loss_fn(emb_a, emb_p, emb_n)\n",
    "        acc = (F.pairwise_distance(emb_a, emb_p) < F.pairwise_distance(emb_a, emb_n)).float().mean()\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        wav_a, wav_p, wav_n = batch\n",
    "        emb_a = self(wav_a)\n",
    "        emb_p = self(wav_p)\n",
    "        emb_n = self(wav_n)\n",
    "\n",
    "        loss = self.loss_fn(emb_a, emb_p, emb_n)\n",
    "        acc = (F.pairwise_distance(emb_a, emb_p) < F.pairwise_distance(emb_a, emb_n)).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        wav_a, wav_p, wav_n = batch\n",
    "        emb_a = self(wav_a)\n",
    "        emb_p = self(wav_p)\n",
    "        emb_n = self(wav_n)\n",
    "\n",
    "        loss = self.loss_fn(emb_a, emb_p, emb_n)\n",
    "        acc = (F.pairwise_distance(emb_a, emb_p) < F.pairwise_distance(emb_a, emb_n)).float().mean()\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_df, _ = train_test_split(self.df, test_size=0.2, random_state=42, stratify=self.df['label'])\n",
    "        ds = CachedAudioDataset(\n",
    "            train_df,\n",
    "            self.root_dir,\n",
    "            self.noise_files,\n",
    "            training=True,\n",
    "            expansion_factor=5\n",
    "        )\n",
    "        return DataLoader(ds, batch_size=64, shuffle=True, num_workers=2, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        _, val_df = train_test_split(self.df, test_size=0.2, random_state=42, stratify=self.df['label'])\n",
    "        ds = CachedAudioDataset(val_df, self.root_dir, noise_files=None, training=False)\n",
    "        return DataLoader(ds, batch_size=64, shuffle=False, num_workers=2, persistent_workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4714d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# ==========================================\n",
    "# KONFIGURACJA UNIKALNEGO TRENINGU\n",
    "# ==========================================\n",
    "\n",
    "#OPCJALNIE: customowy dodatek nazy runu\n",
    "model_big_name = \"ResNet_Triplet_big_head_more_dropout\"\n",
    "\n",
    "\n",
    "# 1. Tworzymy unikalnÄ… nazwÄ™ folderu na podstawie daty i godziny\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "run_name = f\"{model_big_name}_{timestamp}\"\n",
    "checkpoint_dir = os.path.join(\"checkpoints\", run_name)\n",
    "\n",
    "# Tworzymy folder fizycznie\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "print(f\"ðŸ“‚ Checkpointy z tego treningu trafiÄ… do: {checkpoint_dir}\")\n",
    "\n",
    "# ==========================================\n",
    "# CALLBACKI I LOGGER\n",
    "# ==========================================\n",
    "\n",
    "# 2. Checkpoint najlepszego modelu wg Accuracy\n",
    "checkpoint_best = ModelCheckpoint(\n",
    "    monitor=\"val_acc\",\n",
    "    mode=\"max\",\n",
    "    dirpath=checkpoint_dir,\n",
    "    filename=\"best-epoch={epoch:02d}-acc={val_acc:.4f}\",\n",
    "    save_top_k=1,\n",
    "    auto_insert_metric_name=False\n",
    ")\n",
    "\n",
    "# 3. Checkpoint okresowy (co 5 epok)\n",
    "checkpoint_periodic = ModelCheckpoint(\n",
    "    dirpath=checkpoint_dir,\n",
    "    filename=\"periodic-epoch={epoch:02d}\",\n",
    "    every_n_epochs=5,\n",
    "    save_last=True,\n",
    "    save_top_k=-1\n",
    ")\n",
    "\n",
    "# 4. WandB Logger\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"siamese-audio-classifier\",\n",
    "    entity=\"deep-neural-network-course\",\n",
    "    name=run_name,\n",
    "    log_model=False\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# START TRENINGU\n",
    "# ==========================================\n",
    "\n",
    "if local:\n",
    "    ROOT_DIR = \"dataset/MAD_dataset\"  # upewnij siÄ™, Å¼e to poprawna Å›cieÅ¼ka!\n",
    "else:\n",
    "    ROOT_DIR = \"/content/dataset/MAD_dataset\" # upewnij siÄ™, Å¼e to poprawna Å›cieÅ¼ka!\n",
    "\n",
    "\n",
    "model = ResNetTripletGPU(\n",
    "    df=df_full,\n",
    "    root_dir=ROOT_DIR,\n",
    "    noise_files=noise_files,\n",
    "    margin=0.5\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[checkpoint_best, checkpoint_periodic],\n",
    "    log_every_n_steps=10,\n",
    "    precision=32,\n",
    "    gradient_clip_val=1.0\n",
    ")\n",
    "\n",
    "print(f\"ðŸš€ Rozpoczynam trening: {run_name}\")\n",
    "trainer.fit(model)\n",
    "\n",
    "print(\"Trening zakoÅ„czony.\")\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab8ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "#OPCJALNIE: customowy dodatek nazy runu\n",
    "model_pet_name = \"bigger_head_more_drop\" # np. V1, V2 itp.\n",
    "\n",
    "print(\"ðŸ› ï¸ KONFIGURACJA ÅšRODOWISKA I FOLDERÃ“W...\")\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    # --- Montowanie Dysku Google ---\n",
    "    if os.path.exists('/content/drive') and not os.path.exists('/content/drive/MyDrive'):\n",
    "        print(\"âš ï¸ Wykryto bÅ‚Ä™dne montowanie. Naprawiam...\")\n",
    "        shutil.rmtree('/content/drive')\n",
    "    if not os.path.exists('/content/drive'):\n",
    "        drive.mount('/content/drive', force_remount=True)\n",
    "    BASE_DIR = \"/content/drive/MyDrive/studia/ProjektGsn/Models\"\n",
    "else:\n",
    "    # ÅšcieÅ¼ka lokalna\n",
    "    BASE_DIR = os.path.abspath(\"Models\")\n",
    "\n",
    "# Tworzymy unikalnÄ… nazwÄ™ runu\n",
    "if 'run_name' not in globals():\n",
    "    run_name = f\"Run_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "\n",
    "TARGET_RUN_DIR = os.path.join(BASE_DIR, run_name)\n",
    "os.makedirs(TARGET_RUN_DIR, exist_ok=True)\n",
    "print(f\"âœ… Folder na wyniki: {TARGET_RUN_DIR}\")\n",
    "\n",
    "# ==========================================\n",
    "# Testowanie najlepszego modelu\n",
    "# ==========================================\n",
    "print(\"\\nðŸ“Š ROZPOCZYNAM TESTOWANIE NAJLEPSZEGO MODELU...\")\n",
    "\n",
    "if 'ROOT_DIR' not in globals():\n",
    "    ROOT_DIR = \"dataset/MAD_dataset\" if not IS_COLAB else \"/content/dataset/MAD_dataset\"\n",
    "\n",
    "test_csv_path = os.path.join(ROOT_DIR, \"test.csv\")\n",
    "if not os.path.exists(test_csv_path):\n",
    "    test_csv_path = os.path.join(ROOT_DIR, \"test.csv\")  # fallback lokalny\n",
    "\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "def fix_test_path(path):\n",
    "    path = str(path)\n",
    "    if not path.startswith(\"test/\") and not path.startswith(\"training/\"):\n",
    "        return os.path.join(\"test\", path)\n",
    "    return path\n",
    "\n",
    "df_test['path'] = df_test['path'].apply(fix_test_path)\n",
    "\n",
    "test_ds = CachedAudioDataset(df_test, root_dir=ROOT_DIR, noise_files=None, training=False, expansion_factor=1)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Pobieranie Å›cieÅ¼ki najlepszego modelu\n",
    "if 'checkpoint_best' in globals():\n",
    "    best_local_path = checkpoint_best.best_model_path\n",
    "    last_local_path = checkpoint_best.last_model_path\n",
    "else:\n",
    "    local_dir = f\"checkpoints/{run_name}\"\n",
    "    files = glob.glob(f\"{local_dir}/best*.ckpt\")\n",
    "    best_local_path = files[0] if files else None\n",
    "    last_local_path = os.path.join(local_dir, \"last.ckpt\")\n",
    "\n",
    "if not best_local_path or not os.path.exists(best_local_path):\n",
    "    raise FileNotFoundError(\"Nie znaleziono modelu 'best' w folderze checkpoints!\")\n",
    "\n",
    "trainer.logger = None  # wyÅ‚Ä…cz logger\n",
    "best_model = ResNetTripletGPU.load_from_checkpoint(best_local_path, df=df_full, root_dir=ROOT_DIR, noise_files=[])\n",
    "time_ms_start = datetime.datetime.now()\n",
    "results = trainer.test(best_model, dataloaders=test_loader)\n",
    "time_ms_end = datetime.datetime.now()\n",
    "time_taken = (time_ms_end - time_ms_start).total_seconds() * 1000\n",
    "print(f\"Czas testowania: {time_taken:.2f} ms\")\n",
    "avg_inference_time = time_taken / len(test_ds)\n",
    "print(f\"Åšredni czas inferencji na prÃ³bkÄ™: {avg_inference_time:.4f} ms\")\n",
    "\n",
    "acc, loss = results[0]['test_acc'], results[0]['test_loss']\n",
    "\n",
    "print(f\"\\nðŸ“ WYNIKI BEST: ACC={acc:.4f}, LOSS={loss:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# Kopiowanie lub zapis lokalny\n",
    "# ==========================================\n",
    "print(f\"\\nðŸšš Zapis wynikÃ³w do folderu: {TARGET_RUN_DIR}\")\n",
    "\n",
    "# A) Zapis najlepszego modelu\n",
    "best_filename = f\"{model_pet_name}BEST_ACC={acc:.4f}_LOSS={loss:.4f}_time={avg_inference_time:.4f}.ckpt\"\n",
    "target_best = os.path.join(TARGET_RUN_DIR, best_filename)\n",
    "try:\n",
    "    shutil.copy(best_local_path, target_best)\n",
    "    print(f\"âœ… Zapisano NAJLEPSZY model: {best_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ BÅ‚Ä…d kopiowania BEST: {e}\")\n",
    "\n",
    "# B) Zapis ostatniego stanu\n",
    "if last_local_path and os.path.exists(last_local_path):\n",
    "    last_filename = \"LAST_STATE.ckpt\"\n",
    "    target_last = os.path.join(TARGET_RUN_DIR, last_filename)\n",
    "    try:\n",
    "        shutil.copy(last_local_path, target_last)\n",
    "        print(f\"âœ… Zapisano OSTATNI model: {last_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ BÅ‚Ä…d kopiowania LAST: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Nie znaleziono pliku 'last.ckpt'. JeÅ›li chcesz, ustaw save_last=True przy treningu.\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ ZakoÅ„czono! SprawdÅº folder z wynikami.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
