{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e9c29a3e",
      "metadata": {
        "id": "e9c29a3e"
      },
      "source": [
        "Import bibliotek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kmyjlSQ03oHO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmyjlSQ03oHO",
        "outputId": "9e00bf38-9d1e-456c-dedd-6fc5e4600e7b"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install torchaudio\n",
        "!pip install lightning\n",
        "!pip install kagglehub\n",
        "!pip install scikit-learn\n",
        "!pip install ipython\n",
        "!pip install soundfile\n",
        "!pip install wandb\n",
        "!pip install onnx onnxscript onnxruntime\n",
        "\n",
        "!pip install \"resampy>=0.4.0\"\n",
        "!pip install numpy scipy tqdm requests julius\n",
        "!pip install torchopenl3 --no-deps\n",
        "!pip install torchcodec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "dbc91345",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbc91345",
        "outputId": "f140473b-68c7-4402-86d1-43bb8b909484"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import torchaudio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import LightningDataModule\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "import kagglehub\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from pathlib import Path\n",
        "import torchmetrics\n",
        "import torch.optim as optim\n",
        "import torchopenl3\n",
        "import numpy as np\n",
        "import wandb\n",
        "from IPython.display import Audio\n",
        "from tqdm.auto import tqdm\n",
        "import gdown\n",
        "import glob\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bd2bab5",
      "metadata": {
        "id": "6bd2bab5"
      },
      "source": [
        "Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e4f0a777",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4f0a777",
        "outputId": "85359222-4c11-4211-bf23-408f42bd428d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ju偶 istnieje w folderze 'dataset'. Pomijam pobieranie.\n"
          ]
        }
      ],
      "source": [
        "target_dir = \"dataset\"\n",
        "\n",
        "if os.path.exists(target_dir) and len(os.listdir(target_dir)) > 0:\n",
        "    print(f\"Dataset ju偶 istnieje w folderze '{target_dir}'. Pomijam pobieranie.\")\n",
        "else:\n",
        "    print(\"Dataset nie znaleziony. Rozpoczynam pobieranie...\")\n",
        "    path = kagglehub.dataset_download(\"junewookim/mad-dataset-military-audio-dataset\")\n",
        "    print(\"Cache KaggleHub:\", path)\n",
        "\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    shutil.copytree(path, target_dir, dirs_exist_ok=True)\n",
        "    print(\"Pobrano i zapisano do:\", target_dir)\n",
        "\n",
        "noise_folder = \"dataset/noises\"\n",
        "os.makedirs(noise_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oIKVVPFV-2Xf",
      "metadata": {
        "id": "oIKVVPFV-2Xf"
      },
      "source": [
        "### Pobieranie szum贸w z dysku google\n",
        "Ten fragment ma za zadanie pobra szumy na colaba z dysku google je偶eli jakiego dzwiku szum贸w nie ma w docelowym folderze. Gdy kto chce doda inne szumy to nale偶y doda je do folderu pod tym adresem URL: https://drive.google.com/drive/folders/14Q_0KNDXACkFQ2oTF1T-gnjIaNbNuaKL?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1-q8o1te8L5t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-q8o1te8L5t",
        "outputId": "49dfd2bf-5cad-4117-ff97-d4498a4ea66d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder dataset/noises zawiera ju偶 5 plik贸w. Pomijam pobieranie.\n",
            "Gotowe. Dostpnych plik贸w szumu do treningu: 5\n"
          ]
        }
      ],
      "source": [
        "url = \"https://drive.google.com/drive/folders/14Q_0KNDXACkFQ2oTF1T-gnjIaNbNuaKL?usp=sharing\"\n",
        "output_folder = \"dataset/noises\"\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "existing_wavs = list(Path(output_folder).glob(\"*.wav\"))\n",
        "\n",
        "if len(existing_wavs) > 0:\n",
        "    print(f\"Folder {output_folder} zawiera ju偶 {len(existing_wavs)} plik贸w. Pomijam pobieranie.\")\n",
        "else:\n",
        "    print(\"Folder pusty. Rozpoczynam pobieranie szum贸w z Google Drive...\")\n",
        "    try:\n",
        "        gdown.download_folder(url, output=output_folder, quiet=False, use_cookies=False)\n",
        "        print(\"Pobieranie zakoczone sukcesem.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Wystpi bd podczas pobierania: {e}\")\n",
        "        print(\"Upewnij si, 偶e link na Google Drive jest ustawiony jako 'Ka偶dy majcy link' (Anyone with the link).\")\n",
        "\n",
        "noise_files_list = list(Path(output_folder).glob(\"*.wav\"))\n",
        "print(f\"Gotowe. Dostpnych plik贸w szumu do treningu: {len(noise_files_list)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3908d177",
      "metadata": {
        "id": "3908d177"
      },
      "source": [
        "### Funkcja dodajca szum\n",
        "Funkcja pomocnicza do augmentacji danych poprzez dodawanie szumu do nagra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "49651be6",
      "metadata": {
        "id": "49651be6"
      },
      "outputs": [],
      "source": [
        "def rms_normalize(wav, eps=1e-8):\n",
        "    rms = torch.sqrt(torch.mean(wav ** 2))\n",
        "    return wav / (rms + eps)\n",
        "\n",
        "\n",
        "def aggressive_augment(waveform, noise_files,do_augment=True, sr=48000):\n",
        "    \"\"\"\n",
        "    Zaawansowana augmentacja: losowy Gain, losowy SNR, losowy fragment szumu.\n",
        "    \"\"\"\n",
        "    # 1. Losowe wzmocnienie (Gain) - symulacja r贸偶nych odlegoci od mikrofonu\n",
        "    gain = random.uniform(0.5, 1.5)\n",
        "    aug_wav = waveform * gain\n",
        "\n",
        "    # 2. Dodawanie szumu\n",
        "    if noise_files and len(noise_files) > 0:\n",
        "        noise_path = random.choice(noise_files)\n",
        "        # adowanie szumu\n",
        "        noise_wav, noise_sr = torchaudio.load(noise_path)\n",
        "\n",
        "        # Resample szumu jeli trzeba\n",
        "        if noise_sr != sr:\n",
        "            resampler = torchaudio.transforms.Resample(noise_sr, sr)\n",
        "            noise_wav = resampler(noise_wav)\n",
        "\n",
        "        # Upewnij si, 偶e szum jest mono\n",
        "        if noise_wav.shape[0] > 1:\n",
        "            noise_wav = noise_wav.mean(dim=0, keepdim=True)\n",
        "\n",
        "        L_signal = aug_wav.shape[1]\n",
        "        L_noise = noise_wav.shape[1]\n",
        "\n",
        "        # Dopasowanie dugoci (Twoje wymaganie: losowe fragmenty)\n",
        "        if L_noise < L_signal:\n",
        "            repeats = int(L_signal / L_noise) + 1\n",
        "            noise_wav = noise_wav.repeat(1, repeats)\n",
        "            noise_wav = noise_wav[:, :L_signal]\n",
        "        elif L_noise > L_signal:\n",
        "            start_max = L_noise - L_signal\n",
        "            start = random.randint(0, start_max)\n",
        "            noise_wav = noise_wav[:, start : start + L_signal]\n",
        "\n",
        "        # Mieszanie z losowym SNR (Signal-to-Noise Ratio)\n",
        "        # SNR 5 (gony szum) do 25 (cichy szum)\n",
        "        snr_db = random.uniform(10.0, 30.0)\n",
        "\n",
        "        signal_power = aug_wav.norm(p=2)\n",
        "        noise_power = noise_wav.norm(p=2)\n",
        "\n",
        "        if noise_power > 0:\n",
        "            snr = 10 ** (snr_db / 20)\n",
        "            scale = signal_power / (noise_power * snr + 1e-9)\n",
        "            if do_augment:\n",
        "                aug_wav = aug_wav + (noise_wav * scale)\n",
        "\n",
        "    # 3. Clip (symulacja przesteru)\n",
        "    if random.random() > 0.3:\n",
        "        aug_wav = torch.clamp(aug_wav, -0.95, 0.95)\n",
        "\n",
        "    aug_wav = rms_normalize(aug_wav)\n",
        "    return aug_wav"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WemQAI-u2CWV",
      "metadata": {
        "id": "WemQAI-u2CWV"
      },
      "source": [
        "### Klasa ekstraktora cech OpenL3\n",
        "Klasa wrapper dla modelu OpenL3 su偶ca do ekstrakcji embedding贸w z plik贸w audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "316tU6uk16_t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "316tU6uk16_t",
        "outputId": "1588f002-7e5d-44bc-cf3d-98429b328b55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inicjalizacja TorchOpenL3 Feature Extractor...\n",
            "adowanie modelu TorchOpenL3: mel128, music, embedding_size=512\n",
            "OpenL3 ekstraktor zaadowany na urzdzeniu: cuda\n"
          ]
        }
      ],
      "source": [
        "class OpenL3FeatureExtractor:\n",
        "    \"\"\"\n",
        "    Ekstraktor cech audio za pomoc modelu torchopenl3 (PyTorch)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_repr=\"mel128\", content_type=\"music\", embedding_size=512):\n",
        "        \"\"\"\n",
        "        input_repr: \"mel128\" lub \"mel256\"\n",
        "        content_type: \"music\" lub \"env\" (w torchopenl3 'environmental' to 'env')\n",
        "        embedding_size: 512 lub 6144\n",
        "        \"\"\"\n",
        "        if content_type == \"environmental\":\n",
        "            content_type = \"env\"\n",
        "\n",
        "        print(f\"adowanie modelu TorchOpenL3: {input_repr}, {content_type}, embedding_size={embedding_size}\")\n",
        "\n",
        "        self.model = torchopenl3.models.load_audio_embedding_model(\n",
        "            input_repr=input_repr,\n",
        "            content_type=content_type,\n",
        "            embedding_size=embedding_size\n",
        "        )\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        self.input_repr = input_repr\n",
        "        self.content_type = content_type\n",
        "        self.embedding_size = embedding_size\n",
        "        self.sample_rate = 8000\n",
        "\n",
        "    def extract_features(self, waveform):\n",
        "        \"\"\"\n",
        "        waveform: [channels, samples] lub [batch, channels, samples]\n",
        "        \"\"\"\n",
        "\n",
        "        if waveform.dim() == 3:   # [batch, channels, samples]\n",
        "            waveform = waveform.mean(dim=1)  # [batch, samples]\n",
        "        elif waveform.dim() == 2: # [channels, samples]\n",
        "            waveform = waveform.unsqueeze(0) # [1, samples]\n",
        "\n",
        "        waveform = waveform.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embeddings, _ = torchopenl3.get_audio_embedding(\n",
        "                waveform,\n",
        "                sr=48000,\n",
        "                model=self.model,\n",
        "                hop_size=0.1,\n",
        "                verbose=False\n",
        "            )\n",
        "\n",
        "        aggregated = embeddings.mean(dim=1)  # mean pooling po czasie\n",
        "        return aggregated.cpu()\n",
        "\n",
        "\n",
        "\n",
        "print(\"Inicjalizacja TorchOpenL3 Feature Extractor...\")\n",
        "feature_extractor = OpenL3FeatureExtractor(\n",
        "    input_repr=\"mel128\",\n",
        "    content_type=\"music\",\n",
        "    embedding_size=512\n",
        ")\n",
        "print(f\"OpenL3 ekstraktor zaadowany na urzdzeniu: {feature_extractor.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "rPmPApCn2Omb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "b7a2ede23a9f48cba87a6537e7dcc175",
            "bc63bdd4148d486491d05c457702e3c5",
            "d9dca6dca95f4d07bfeb6adf686cc12c",
            "8a58fac3b93f45e79c6107da71965f1b",
            "86fbe66429b4492a8c321c0c1ad67a97",
            "53bfc01f0af84289a082908ea1c0ebbe",
            "de25691cb3f341ec95820440ce8f2f6f",
            "6393b40bc0164d4090027af3792d3565",
            "bde4fc0d1e93414fa5dff600b3d5ac0b",
            "73b0d4e459c44923ac7c2f3c8d8cda38",
            "ab9277013e364f51900f56fc55f7782c"
          ]
        },
        "id": "rPmPApCn2Omb",
        "outputId": "e81e33e3-889c-4769-bfb9-37ce8eaf4ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generowanie datasetu. Wersji na plik: 5\n",
            "Folder docelowy: dataset/processed_augmented\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "068f7f557e434044af45ee7e233fd458",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/6429 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nowy rozmiar datasetu: 32145\n"
          ]
        }
      ],
      "source": [
        "def generate_augmented_dataset(\n",
        "    df,\n",
        "    root_dir,\n",
        "    output_base_dir,\n",
        "    feature_extractor,\n",
        "    noise_files,\n",
        "    do_agument=True,\n",
        "    augmentations_per_file=5\n",
        "):\n",
        "    # Tworzenie struktur folder贸w\n",
        "    audio_out_dir = os.path.join(output_base_dir, \"audio\")\n",
        "    features_out_dir = os.path.join(output_base_dir, \"features\")\n",
        "\n",
        "    os.makedirs(audio_out_dir, exist_ok=True)\n",
        "    os.makedirs(features_out_dir, exist_ok=True)\n",
        "\n",
        "    new_data = []\n",
        "\n",
        "    print(f\"Generowanie datasetu. Wersji na plik: {augmentations_per_file}\")\n",
        "    print(f\"Folder docelowy: {output_base_dir}\")\n",
        "\n",
        "    # Upewnij si, 偶e model jest na GPU\n",
        "    feature_extractor.model.to(feature_extractor.device)\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        original_path = str(row['path'])\n",
        "        label = row['label']\n",
        "        full_path = os.path.join(root_dir, original_path)\n",
        "\n",
        "        # Nazwa bazowa pliku (bez .wav)\n",
        "        filename_base = os.path.basename(original_path).replace(\".wav\", \"\")\n",
        "\n",
        "        try:\n",
        "            # 1. Wczytaj orygina\n",
        "            wav, sr = torchaudio.load(full_path)\n",
        "\n",
        "            # Resample do 48k (OpenL3 wymaga 48k)\n",
        "            if sr != 48000:\n",
        "                wav = torchaudio.transforms.Resample(sr, 48000)(wav)\n",
        "\n",
        "            # Pad/Trim do staej dugoci (ok 3.3 sekundy)\n",
        "            target_len = 160000\n",
        "            if wav.shape[1] > target_len:\n",
        "                wav = wav[:, :target_len]\n",
        "            else:\n",
        "                wav = F.pad(wav, (0, target_len - wav.shape[1]))\n",
        "\n",
        "            # --- Ptla augmentacji ---\n",
        "            for i in range(augmentations_per_file):\n",
        "                new_filename = f\"{filename_base}_aug_{i}\"\n",
        "                wav_save_path = os.path.join(audio_out_dir, f\"{new_filename}.wav\")\n",
        "                feat_save_path = os.path.join(features_out_dir, f\"{new_filename}.pt\")\n",
        "\n",
        "                # Jeli pliki ju偶 istniej, dodaj do listy i pomi obliczenia (cache)\n",
        "                if os.path.exists(wav_save_path) and os.path.exists(feat_save_path):\n",
        "                    new_data.append({\n",
        "                        \"path\": wav_save_path,\n",
        "                        \"feature_path\": feat_save_path,\n",
        "                        \"label\": label\n",
        "                    })\n",
        "                    continue\n",
        "\n",
        "                # A. Augmentacja\n",
        "                current_wav = wav.clone()\n",
        "                # U偶ywamy nowej funkcji augmentacji\n",
        "\n",
        "                noisy_wav = aggressive_augment(current_wav, noise_files,do_agument, sr=48000)\n",
        "\n",
        "                # B. Ekstrakcja cech\n",
        "                with torch.no_grad():\n",
        "                    # extract_features zwraca [512] (dziki .mean() wewntrz Twojej klasy)\n",
        "                    features = feature_extractor.extract_features(noisy_wav)\n",
        "                    if features.dim() > 1:\n",
        "                        features = features.squeeze(0) # Upewnij si 偶e mamy [512]\n",
        "\n",
        "                # C. Zapis\n",
        "                torchaudio.save(wav_save_path, noisy_wav, 48000)\n",
        "                torch.save(features.cpu(), feat_save_path)\n",
        "\n",
        "                new_data.append({\n",
        "                    \"path\": wav_save_path,\n",
        "                    \"feature_path\": feat_save_path,\n",
        "                    \"label\": label\n",
        "                })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Bd przy pliku {original_path}: {e}\")\n",
        "\n",
        "    # Zwracamy nowy DataFrame z wygenerowanymi cie偶kami\n",
        "    return pd.DataFrame(new_data)\n",
        "\n",
        "# Setup\n",
        "features_cache_path = \"dataset/processed_augmented\" # Nowy folder na przetworzone dane\n",
        "noise_folder_path = \"dataset/MAD_dataset/noise\" # lub gdzie masz szumy\n",
        "noise_files_list = list(Path(noise_folder_path).glob(\"*.wav\"))\n",
        "\n",
        "df_full = pd.read_csv(\"dataset/MAD_dataset/training.csv\")\n",
        "\n",
        "# Wywoanie generatora\n",
        "df_augmented = generate_augmented_dataset(\n",
        "    df=df_full, # Tw贸j oryginalny DataFrame\n",
        "    root_dir=\"dataset/MAD_dataset\",\n",
        "    output_base_dir=features_cache_path,\n",
        "    feature_extractor=feature_extractor,\n",
        "    noise_files=noise_files_list,\n",
        "    do_agument=True,\n",
        "    augmentations_per_file=5  # 5 wersji na ka偶dy plik -> 5x wicej danych!\n",
        ")\n",
        "\n",
        "print(f\"Nowy rozmiar datasetu: {len(df_augmented)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "795d1b31",
      "metadata": {
        "id": "795d1b31"
      },
      "source": [
        "### Klasa Dataset na surowym audio\n",
        "Podstawowa klasa Dataset zwracajca pary nagra (surowe waveformy) oraz informacj czy nale偶 do tej samej klasy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a2fdc752",
      "metadata": {
        "id": "a2fdc752"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class SiameseAudioDataset(Dataset):\n",
        "    def __init__(self, df, pairs_per_sample=1):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.pairs = []\n",
        "\n",
        "        label_groups = self.df.groupby(\"label\").indices\n",
        "\n",
        "        for idx, row in self.df.iterrows():\n",
        "            label = row[\"label\"]\n",
        "\n",
        "            # Positive\n",
        "            pos_indices = label_groups[label]\n",
        "            pos_idx = idx\n",
        "            while pos_idx == idx:\n",
        "                pos_idx = random.choice(pos_indices)\n",
        "\n",
        "            self.pairs.append((idx, pos_idx, 1))\n",
        "\n",
        "            # Negative\n",
        "            neg_label = random.choice([l for l in label_groups.keys() if l != label])\n",
        "            neg_idx = random.choice(label_groups[neg_label])\n",
        "            self.pairs.append((idx, neg_idx, 0))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        idx_a, idx_b, same_label = self.pairs[idx]\n",
        "\n",
        "        row_a = self.df.iloc[idx_a]\n",
        "        row_b = self.df.iloc[idx_b]\n",
        "\n",
        "        feat_a = torch.load(row_a[\"feature_path\"])\n",
        "        feat_b = torch.load(row_b[\"feature_path\"])\n",
        "\n",
        "\n",
        "        dummy = torch.empty(1)\n",
        "        return dummy, row_a[\"label\"], dummy, row_b[\"label\"], same_label, 48000, feat_a, feat_b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9f6d2069",
      "metadata": {
        "id": "9f6d2069"
      },
      "outputs": [],
      "source": [
        "def siamese_collate(batch):\n",
        "    a = torch.stack([item[0] for item in batch])\n",
        "    label_a = torch.tensor([item[1] for item in batch], dtype=torch.long)\n",
        "    b = torch.stack([item[2] for item in batch])\n",
        "    label_b = torch.tensor([item[3] for item in batch], dtype=torch.long)\n",
        "    same_label = torch.tensor([item[4] for item in batch], dtype=torch.long)\n",
        "    sample_rate = batch[0][5]\n",
        "\n",
        "    features_a = torch.stack([item[6] for item in batch]) if batch[0][6] is not None else None\n",
        "    features_b = torch.stack([item[7] for item in batch]) if batch[0][7] is not None else None\n",
        "\n",
        "    return a, label_a, b, label_b, same_label, sample_rate, features_a, features_b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c36865f",
      "metadata": {
        "id": "9c36865f"
      },
      "source": [
        "### DataModule dla surowego audio\n",
        "Klasa LightningDataModule zarzdzajca datasetami treningowymi i walidacyjnymi dla surowego audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "544f1ea8",
      "metadata": {
        "id": "544f1ea8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SiameseAudioDataModule(LightningDataModule):\n",
        "    def __init__(self, df, batch_size=32, num_workers=4): # usunito features_dir\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        train_df, val_df = train_test_split(self.df, test_size=0.2, random_state=42, stratify=self.df['label'])\n",
        "        self.train_ds = SiameseAudioDataset(train_df) # Tylko DF\n",
        "        self.val_ds = SiameseAudioDataset(val_df)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True,\n",
        "                          num_workers=self.num_workers, collate_fn=siamese_collate)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=False,\n",
        "                          num_workers=self.num_workers, collate_fn=siamese_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "184bfa04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "184bfa04",
        "outputId": "d660a4c4-a4e3-4444-ac6c-0ee7f3bc128e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features shape: torch.Size([32, 512])\n",
            "Dziaa!\n"
          ]
        }
      ],
      "source": [
        "dm_test = SiameseAudioDataModule(\n",
        "    df=df_augmented,      # <--- ZMIANA: u偶ywamy nowego DataFrame z wygenerowanymi cechami\n",
        "    batch_size=32,\n",
        "    num_workers=4\n",
        "    # features_dir - USUNITO (klasa ju偶 tego nie przyjmuje)\n",
        ")\n",
        "dm_test.setup()\n",
        "batch = next(iter(dm_test.train_dataloader()))\n",
        "print(\"Features shape:\", batch[6].shape) # Powinno by [8, 512]\n",
        "print(\"Dziaa!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df814cfe",
      "metadata": {
        "id": "df814cfe"
      },
      "source": [
        "### Model Syjamski (LightningModule)\n",
        "Definicja modelu sieci neuronowej (klasyfikatora), kt贸ry przyjmuje r贸偶nic cech dw贸ch nagra i decyduje czy s to te same klasy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "8662a542",
      "metadata": {
        "id": "8662a542"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Blok rezydualny dla sieci MLP.\n",
        "    Pozwala budowa gbokie sieci bez problemu zanikajcego gradientu.\n",
        "    x -> [Linear->BN->ReLU->Dropout->Linear->BN] + x -> ReLU\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_dim, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim)\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.block(x)\n",
        "        out += identity  # Skip connection (kluczowe dla gbokich sieci)\n",
        "        return self.relu(out)\n",
        "\n",
        "class SiameseComparator(pl.LightningModule):\n",
        "    def __init__(self, input_dim=1024, hidden_dim=1024, learning_rate=5e-4):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Wejcie: [u, v, |u-v|, u*v] -> 4 * 512 = 2048\n",
        "        concat_dim = input_dim * 4\n",
        "\n",
        "        # 1. Projekcja wejcia do przestrzeni ukrytej (szerokiej)\n",
        "        self.input_projection = nn.Sequential(\n",
        "            nn.Linear(concat_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # 2. Gboka cz sieci (Stack blok贸w rezydualnych)\n",
        "        # To daje nam ekwiwalent ~8-10 gstych warstw, ale stabilnych w treningu\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            ResidualBlock(hidden_dim, dropout_rate=0.2),\n",
        "            ResidualBlock(hidden_dim, dropout_rate=0.2),\n",
        "            ResidualBlock(hidden_dim, dropout_rate=0.2),\n",
        "            ResidualBlock(hidden_dim, dropout_rate=0.2)\n",
        "        )\n",
        "\n",
        "        # 3. Gowa klasyfikacyjna (Head) - zaw偶anie do wyniku\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2), # 1024 -> 512\n",
        "            nn.BatchNorm1d(hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "\n",
        "            nn.Linear(hidden_dim // 2, 512),        \n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "\n",
        "\n",
        "            nn.Linear(256, 1)                       # Wynik (logit)\n",
        "        )\n",
        "\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
        "        self.accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
        "        self.f1_score = torchmetrics.F1Score(task=\"binary\")\n",
        "\n",
        "    def forward(self, feat_a, feat_b):\n",
        "        # Normalizacja L2 nadal jest kluczowa!\n",
        "        u = F.normalize(feat_a, p=2, dim=1)\n",
        "        v = F.normalize(feat_b, p=2, dim=1)\n",
        "\n",
        "        # Bogate cechy\n",
        "        features = torch.cat([\n",
        "            u,\n",
        "            v,\n",
        "            torch.abs(u - v),\n",
        "            u * v\n",
        "        ], dim=1)\n",
        "\n",
        "        # Przepyw przez sie\n",
        "        x = self.input_projection(features)\n",
        "        x = self.res_blocks(x)\n",
        "        return self.head(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        _, _, _, _, same_label, _, features_a, features_b = batch\n",
        "\n",
        "        logits = self(features_a, features_b)\n",
        "        logits = logits.squeeze(1)\n",
        "\n",
        "        loss = self.loss_fn(logits, same_label.float())\n",
        "\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).long()\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", self.accuracy(preds, same_label), prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, _, _, _, same_label, _, features_a, features_b = batch\n",
        "\n",
        "        logits = self(features_a, features_b)\n",
        "        logits = logits.squeeze(1)\n",
        "        loss = self.loss_fn(logits, same_label.float())\n",
        "\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.5).long()\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", self.accuracy(preds, same_label), prog_bar=True)\n",
        "        self.log(\"val_f1\", self.f1_score(preds, same_label), prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Dla wikszej sieci OneCycleLR czsto dziaa lepiej i szybciej zbiega\n",
        "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.learning_rate, weight_decay=1e-3)\n",
        "\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='min', factor=0.5, patience=3\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c6444c",
      "metadata": {
        "id": "e8c6444c"
      },
      "source": [
        "### Trening modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "jb5tbFRS3iv4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464,
          "referenced_widgets": [
            "716b69f04898431cba21c0661706df02",
            "879a7e2436bc4b43b8d03a982588c2dd"
          ]
        },
        "id": "jb5tbFRS3iv4",
        "outputId": "c7dc7170-c02b-455e-eea8-cd1a5fd9da11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "You are using a CUDA device ('NVIDIA GeForce RTX 4050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rozpoczynam trening z logowaniem do W&B...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>wandb/run-20260106_204621-9jnwi7ax</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/deep-neural-network-course/siamese-audio-classifier/runs/9jnwi7ax' target=\"_blank\">Iwo_Rymer_test_changed_siamese_dataset</a></strong> to <a href='https://wandb.ai/deep-neural-network-course/siamese-audio-classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/deep-neural-network-course/siamese-audio-classifier' target=\"_blank\">https://wandb.ai/deep-neural-network-course/siamese-audio-classifier</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/deep-neural-network-course/siamese-audio-classifier/runs/9jnwi7ax' target=\"_blank\">https://wandb.ai/deep-neural-network-course/siamese-audio-classifier/runs/9jnwi7ax</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name             | Type              | Params | Mode  | FLOPs\n",
            "-----------------------------------------------------------------------\n",
            "0 | input_projection | Sequential        | 525 K  | train | 0    \n",
            "1 | res_blocks       | Sequential        | 530 K  | train | 0    \n",
            "2 | head             | Sequential        | 232 K  | train | 0    \n",
            "3 | loss_fn          | BCEWithLogitsLoss | 0      | train | 0    \n",
            "4 | accuracy         | BinaryAccuracy    | 0      | train | 0    \n",
            "5 | f1_score         | BinaryF1Score     | 0      | train | 0    \n",
            "-----------------------------------------------------------------------\n",
            "1.3 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.3 M     Total params\n",
            "5.151     Total estimated model params size (MB)\n",
            "56        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "0         Total Flops\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcc1749f1015493a9b973920bb3aa6b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/iwo/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "376a724515794893b244598c569871d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4d1876205f14764ac7231d6ec9f6e25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/iwo/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 26. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c3f8f3ee9f94f1c9ddb4b6461231cc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4613d35a13584fb197c1ae5b70a5798c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc5a62ea225846d7968c7eb788eedd98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f176b3e46f14eda9ab8eab3f2e5d60f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44477cb999ee4822849edcb3ce2e8401",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "1",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/iwo/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n",
            "socket.send() raised exception.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x7d65d99cf700>> (for post_run_cell), with arguments args (<ExecutionResult object at 7d677006a9e0, execution_count=13 error_before_exec=None error_in_exec=1 info=<ExecutionInfo object at 7d677006b130, raw_cell=\"dm = SiameseAudioDataModule(\n",
            "    df=df_augmented,\n",
            "..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/home/iwo/GSN/siamese-audio-classifier/dataloader.ipynb#X30sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "BrokenPipeError",
          "evalue": "[Errno 32] Broken pipe",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:604\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 604\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:811\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:334\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:46\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, nowait)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncer\u001b[38;5;241m.\u001b[39mrun_soon(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpublish(request))\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_asyncer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/lib/asyncio_manager.py:136\u001b[0m, in \u001b[0;36mAsyncioManager.run\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    133\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schedule(fn, daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RunCancelledError \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/lib/asyncio_manager.py:219\u001b[0m, in \u001b[0;36mAsyncioManager._wrap\u001b[0;34m(self, fn, daemon, name)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m (task \u001b[38;5;241m:=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcurrent_task()):\n\u001b[1;32m    217\u001b[0m         task\u001b[38;5;241m.\u001b[39mset_name(name)\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m daemon:\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/asyncio/streams.py:359\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/lib/asyncio_manager.py:181\u001b[0m, in \u001b[0;36mAsyncioManager.run_soon.<locals>.fn_wrap_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfn_wrap_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m fn()\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUncaught exception in run_soon callback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/lib/service/service_client.py:38\u001b[0m, in \u001b[0;36mServiceClient.publish\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a request without waiting for a response.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_server_request(request)\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/lib/service/service_client.py:64\u001b[0m, in \u001b[0;36mServiceClient._send_server_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     61\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mSerializeToString()\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[0;32m---> 64\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer\u001b[38;5;241m.\u001b[39mdrain()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/asyncio/streams.py:359\u001b[0m, in \u001b[0;36mStreamWriter.drain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mexception()\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing():\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# Wait for protocol.connection_lost() call\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Raise connection closing error if any,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# in a loop would never call connection_lost(), so it\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# would not see an error when the socket is closed.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/lib/service/service_client.py:73\u001b[0m, in \u001b[0;36mServiceClient._forward_responses\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_forward_responses\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m response \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_server_response():\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mailbox\u001b[38;5;241m.\u001b[39mdeliver(response)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
            "File \u001b[0;32m~/GSN/siamese-audio-classifier/.venv/lib/python3.10/site-packages/wandb/sdk/lib/service/service_client.py:87\u001b[0m, in \u001b[0;36mServiceClient._read_server_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_server_response\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerResponse \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m         header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mreadexactly(_HEADER_BYTE_INT_LEN)\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mIncompleteReadError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mpartial:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/asyncio/streams.py:708\u001b[0m, in \u001b[0;36mStreamReader.readexactly\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mIncompleteReadError(incomplete, n)\n\u001b[0;32m--> 708\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadexactly\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer) \u001b[38;5;241m==\u001b[39m n:\n\u001b[1;32m    711\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/asyncio/streams.py:501\u001b[0m, in \u001b[0;36mStreamReader._wait_for_data\u001b[0;34m(self, func_name)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_future()\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.14/lib/python3.10/asyncio/selector_events.py:924\u001b[0m, in \u001b[0;36m_SelectorSocketTransport.write\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer:\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;66;03m# Optimization: try to send now.\u001b[39;00m\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 924\u001b[0m         n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mBlockingIOError\u001b[39;00m, \u001b[38;5;167;01mInterruptedError\u001b[39;00m):\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ],
      "source": [
        "dm = SiameseAudioDataModule(\n",
        "    df=df_augmented,\n",
        "    batch_size=32,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "model = SiameseComparator(input_dim=512, hidden_dim=256, learning_rate=0.001)\n",
        "\n",
        "wandb_logger = WandbLogger(\n",
        "    project=\"siamese-audio-classifier\",\n",
        "    entity=\"deep-neural-network-course\",\n",
        "    name=\"Iwo_Rymer_test_changed_siamese_dataset\",\n",
        "    log_model=\"all\"\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=20,\n",
        "    accelerator=\"auto\",\n",
        "    devices=1,\n",
        "    logger=wandb_logger,\n",
        "    log_every_n_steps=5\n",
        ")\n",
        "\n",
        "print(\"Rozpoczynam trening z logowaniem do W&B...\")\n",
        "trainer.fit(model, datamodule=dm)\n",
        "\n",
        "print(\"Trening zakoczony!\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d60279a3",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "be7becab",
      "metadata": {},
      "source": [
        "***Obliczanie cosilne baseline***\n",
        "(sprawdzenie czy embeddingi si r贸偶ni: jak prawie wszystko pod 1 to Open L3 nie widzi r贸偶nic midzy klasami)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "018303fe",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9169f75b09254cd898bab54a91775805",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def compute_cosine_baseline(\n",
        "    df,\n",
        "    num_pairs=5000,\n",
        "    seed=42\n",
        "):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    label_groups = df.groupby(\"label\").indices\n",
        "    labels = list(label_groups.keys())\n",
        "\n",
        "    positive_sims = []\n",
        "    negative_sims = []\n",
        "\n",
        "    for _ in tqdm(range(num_pairs)):\n",
        "        idx_a = random.randrange(len(df))\n",
        "        row_a = df.iloc[idx_a]\n",
        "        label_a = row_a[\"label\"]\n",
        "\n",
        "        feat_a = torch.load(row_a[\"feature_path\"]).float().squeeze(0)\n",
        "        if torch.isnan(feat_a).any():\n",
        "            continue\n",
        "        feat_a = feat_a / (feat_a.norm(p=2) + 1e-8)\n",
        "\n",
        "        # POSITIVE\n",
        "        pos_idx = idx_a\n",
        "        while pos_idx == idx_a:\n",
        "            pos_idx = random.choice(label_groups[label_a])\n",
        "\n",
        "        feat_p = torch.load(df.iloc[pos_idx][\"feature_path\"]).float().squeeze(0)\n",
        "        if torch.isnan(feat_p).any():\n",
        "            continue\n",
        "        feat_p = feat_p / (feat_p.norm(p=2) + 1e-8)\n",
        "\n",
        "        positive_sims.append(torch.dot(feat_a, feat_p).item())\n",
        "\n",
        "        # NEGATIVE\n",
        "        neg_label = random.choice([l for l in labels if l != label_a])\n",
        "        neg_idx = random.choice(label_groups[neg_label])\n",
        "\n",
        "        feat_n = torch.load(df.iloc[neg_idx][\"feature_path\"]).float().squeeze(0)\n",
        "        if torch.isnan(feat_n).any():\n",
        "            continue\n",
        "        feat_n = feat_n / (feat_n.norm(p=2) + 1e-8)\n",
        "\n",
        "        negative_sims.append(torch.dot(feat_a, feat_n).item())\n",
        "\n",
        "    return np.array(positive_sims), np.array(negative_sims)\n",
        "\n",
        "\n",
        "pos_sims, neg_sims = compute_cosine_baseline(df_augmented, num_pairs=5000)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "plt.hist(pos_sims, bins=50, alpha=0.6, label=\"Positive pairs\")\n",
        "plt.hist(neg_sims, bins=50, alpha=0.6, label=\"Negative pairs\")\n",
        "\n",
        "plt.xlabel(\"Cosine similarity\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Cosine similarity baseline (OpenL3 embeddings)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "35d65701",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== COSINE BASELINE STATS ===\n",
            "Positive: mean=0.994, std=0.008\n",
            "Negative: mean=0.994, std=0.009\n",
            "Accuracy @ threshold=0.5: 0.500\n"
          ]
        }
      ],
      "source": [
        "print(\"=== COSINE BASELINE STATS ===\")\n",
        "print(f\"Positive: mean={pos_sims.mean():.3f}, std={pos_sims.std():.3f}\")\n",
        "print(f\"Negative: mean={neg_sims.mean():.3f}, std={neg_sims.std():.3f}\")\n",
        "\n",
        "# Prosty threshold test\n",
        "threshold = 0.5\n",
        "pos_acc = (pos_sims > threshold).mean()\n",
        "neg_acc = (neg_sims < threshold).mean()\n",
        "print(f\"Accuracy @ threshold={threshold}: {(pos_acc + neg_acc) / 2:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4cf1e68a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0 0.0\n",
            "0.9942584441781044 0.9942747221946716\n"
          ]
        }
      ],
      "source": [
        "print(np.isnan(pos_sims).mean(), np.isnan(neg_sims).mean())\n",
        "print(pos_sims.mean(), neg_sims.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "fe13363d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.2073) tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "wav, _ = torchaudio.load(df_augmented.iloc[0][\"path\"])\n",
        "print(wav.abs().mean(), wav.abs().max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2a8e2a85",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type: <class 'torch.Tensor'>\n",
            "shape: torch.Size([1024])\n",
            "dtype: torch.float32\n",
            "min: nan\n",
            "max: nan\n",
            "mean: nan\n",
            "std: nan\n",
            "any NaN: True\n",
            "any Inf: False\n",
            "norm: nan\n"
          ]
        }
      ],
      "source": [
        "row = df_augmented.iloc[0]\n",
        "feat = torch.load(row[\"feature_path\"])\n",
        "\n",
        "print(\"type:\", type(feat))\n",
        "print(\"shape:\", feat.shape)\n",
        "print(\"dtype:\", feat.dtype)\n",
        "\n",
        "print(\"min:\", feat.min().item())\n",
        "print(\"max:\", feat.max().item())\n",
        "print(\"mean:\", feat.mean().item())\n",
        "print(\"std:\", feat.std().item())\n",
        "\n",
        "print(\"any NaN:\", torch.isnan(feat).any().item())\n",
        "print(\"any Inf:\", torch.isinf(feat).any().item())\n",
        "print(\"norm:\", feat.norm().item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "60c6a30f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>feature_path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dataset/processed_augmented/audio/0_aug_0.wav</td>\n",
              "      <td>dataset/processed_augmented/features/0_aug_0.pt</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dataset/processed_augmented/audio/0_aug_1.wav</td>\n",
              "      <td>dataset/processed_augmented/features/0_aug_1.pt</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dataset/processed_augmented/audio/0_aug_2.wav</td>\n",
              "      <td>dataset/processed_augmented/features/0_aug_2.pt</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dataset/processed_augmented/audio/0_aug_3.wav</td>\n",
              "      <td>dataset/processed_augmented/features/0_aug_3.pt</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dataset/processed_augmented/audio/0_aug_4.wav</td>\n",
              "      <td>dataset/processed_augmented/features/0_aug_4.pt</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            path  \\\n",
              "0  dataset/processed_augmented/audio/0_aug_0.wav   \n",
              "1  dataset/processed_augmented/audio/0_aug_1.wav   \n",
              "2  dataset/processed_augmented/audio/0_aug_2.wav   \n",
              "3  dataset/processed_augmented/audio/0_aug_3.wav   \n",
              "4  dataset/processed_augmented/audio/0_aug_4.wav   \n",
              "\n",
              "                                      feature_path  label  \n",
              "0  dataset/processed_augmented/features/0_aug_0.pt      3  \n",
              "1  dataset/processed_augmented/features/0_aug_1.pt      3  \n",
              "2  dataset/processed_augmented/features/0_aug_2.pt      3  \n",
              "3  dataset/processed_augmented/features/0_aug_3.pt      3  \n",
              "4  dataset/processed_augmented/features/0_aug_4.pt      3  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_augmented.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6uWTIQlJDJy4",
      "metadata": {
        "id": "6uWTIQlJDJy4"
      },
      "source": [
        "**Zapisywanie do ONNX**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Esa5477ICOji",
      "metadata": {
        "id": "Esa5477ICOji"
      },
      "outputs": [],
      "source": [
        "search_pattern = \"siamese-audio-classifier/**/*.ckpt\"\n",
        "list_of_files = glob.glob(search_pattern, recursive=True)\n",
        "\n",
        "if not list_of_files:\n",
        "    print(\"Nie znaleziono checkpointu .ckpt do eksportu!\")\n",
        "else:\n",
        "    latest_checkpoint = max(list_of_files, key=os.path.getctime)\n",
        "    print(f\"Eksportuj model z pliku: {latest_checkpoint}\")\n",
        "\n",
        "    device = torch.device(\"cpu\") # Do eksportu ONNX bezpieczniej u偶y CPU\n",
        "    model_export = SiameseComparator.load_from_checkpoint(latest_checkpoint)\n",
        "    model_export.to(device)\n",
        "    model_export.eval()\n",
        "\n",
        "    dummy_input_a = torch.randn(1, 512, device=device)\n",
        "    dummy_input_b = torch.randn(1, 512, device=device)\n",
        "\n",
        "    onnx_path = \"siamese_audio_comparator.onnx\"\n",
        "\n",
        "    try:\n",
        "        torch.onnx.export(\n",
        "            model_export,\n",
        "            (dummy_input_a, dummy_input_b),\n",
        "            onnx_path,\n",
        "            export_params=True,\n",
        "            opset_version=12,\n",
        "            do_constant_folding=True,\n",
        "            input_names=['feature_vector_a', 'feature_vector_b'],\n",
        "            output_names=['similarity_score'],\n",
        "            dynamic_axes={\n",
        "                'feature_vector_a': {0: 'batch_size'},\n",
        "                'feature_vector_b': {0: 'batch_size'},\n",
        "                'similarity_score': {0: 'batch_size'}\n",
        "            }\n",
        "        )\n",
        "        print(f\"Sukces! Model zapisany jako: {onnx_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Bd podczas eksportu do ONNX: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53bfc01f0af84289a082908ea1c0ebbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6393b40bc0164d4090027af3792d3565": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "716b69f04898431cba21c0661706df02": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_879a7e2436bc4b43b8d03a982588c2dd",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 0/19 <span style=\"color: #6206e0; text-decoration-color: #6206e0\"></span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\"></span> 599/804 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:18  0:00:07</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">33.02it/s</span> <span style=\"font-style: italic\">v_num: dzew train_loss: 0.712     </span>\n                                                                                 <span style=\"font-style: italic\">train_acc: 0.406                  </span>\n</pre>\n",
                  "text/plain": "Epoch 0/19 \u001b[38;2;98;6;224m\u001b[0m\u001b[38;2;98;6;224m\u001b[0m\u001b[38;5;237m\u001b[0m 599/804 \u001b[2m0:00:18  0:00:07\u001b[0m \u001b[2;4m33.02it/s\u001b[0m \u001b[3mv_num: dzew train_loss: 0.712     \u001b[0m\n                                                                                 \u001b[3mtrain_acc: 0.406                  \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "73b0d4e459c44923ac7c2f3c8d8cda38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86fbe66429b4492a8c321c0c1ad67a97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879a7e2436bc4b43b8d03a982588c2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a58fac3b93f45e79c6107da71965f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b0d4e459c44923ac7c2f3c8d8cda38",
            "placeholder": "",
            "style": "IPY_MODEL_ab9277013e364f51900f56fc55f7782c",
            "value": "6429/6429[01:22&lt;00:00,80.47it/s]"
          }
        },
        "ab9277013e364f51900f56fc55f7782c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7a2ede23a9f48cba87a6537e7dcc175": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc63bdd4148d486491d05c457702e3c5",
              "IPY_MODEL_d9dca6dca95f4d07bfeb6adf686cc12c",
              "IPY_MODEL_8a58fac3b93f45e79c6107da71965f1b"
            ],
            "layout": "IPY_MODEL_86fbe66429b4492a8c321c0c1ad67a97"
          }
        },
        "bc63bdd4148d486491d05c457702e3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53bfc01f0af84289a082908ea1c0ebbe",
            "placeholder": "",
            "style": "IPY_MODEL_de25691cb3f341ec95820440ce8f2f6f",
            "value": "100%"
          }
        },
        "bde4fc0d1e93414fa5dff600b3d5ac0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9dca6dca95f4d07bfeb6adf686cc12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6393b40bc0164d4090027af3792d3565",
            "max": 6429,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bde4fc0d1e93414fa5dff600b3d5ac0b",
            "value": 6429
          }
        },
        "de25691cb3f341ec95820440ce8f2f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
